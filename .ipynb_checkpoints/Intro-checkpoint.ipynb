{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a rough outline of the pill counter project for the Garage Team @ Vonage\n",
    "\n",
    "The idea is that a user will be able to shake a pill counter containing n number of pills. The system will be able to predict to number of pills inside the container\n",
    "\n",
    "note: since it is very unlikely to predict the number of pills with many varites of pills, pill sizes and bottle sizes, the pill and bottle will remain constant throughout the expirment. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset:\n",
    "    Currently, I have not been able to find a dataset that contains a corpus of pills being shaken in bottle. \n",
    "    We will have to create our own dataset\n",
    "\n",
    "\n",
    "To create the dataset, we need an audio recording of the following data:\n",
    "    0-10 pills being shaken(5 seconds) in a bottle\n",
    "It is still undeterimined how many audio samples we need in order to perdict the number of pills\n",
    "\n",
    "\n",
    "Classification:\n",
    "Still undeterminted on how to classifiy this data. It could be classification model, only using a subset of pills(0,10,20,30,40,50) as a one hot encoding\n",
    "Howerver, this wont be able to perdict the exact number of pills\n",
    "\n",
    "Audio\n",
    "using Images to Perdict number of pills.\n",
    "use Rasbperry pi to capture images and use to perdict number of pills from camera module\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existing Dataset:\n",
    "    There are some datasets that can be used as a started set to begin the training process on some audio data.\n",
    "    Deep Listing:\n",
    "    https://github.com/jaron/deep-listening\n",
    "    *Used to classify sounds using https://serv.cusp.nyu.edu/projects/urbansounddataset/urbansound8k.html dataset\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research:\n",
    "    http://papers.nips.cc/paper/3674-unsupervised-feature-learning-for-audio-classification-using-convolutional-deep-belief-networks.pdf\n",
    "    https://research.google.com/audioset/\n",
    "    http://papers.nips.cc/paper/3674-unsupervised-feature-learning-for\n",
    "    http://machine-listening.eecs.qmul.ac.uk/bird-audio-detection-challenge/\n",
    "    https://serv.cusp.nyu.edu/projects/urbansounddataset/urbansound8k.html\n",
    "    https://research.google.com/youtube8m/index.html\n",
    "    https://arxiv.org/pdf/1609.09430.pdf\n",
    "    https://research.google.com/pubs/pub45611.html\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
